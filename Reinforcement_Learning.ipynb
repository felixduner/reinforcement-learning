{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DAT405 Introduction to Data Science and AI, 2010-2021, Study Period 1** <br/>\n",
    "**Assignment 5: Reinforcement learning and Classification** <br/>\n",
    "**Due Date: Oct 5, 23:59** <br/>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**What to submit**\n",
    "*   **The entire assignment should be submitted through the notebook. No separate file will be accepted.**<br/>\n",
    "\n",
    "*In the notebook:*\n",
    "*\tState your names and how many hours each person spent on the assignment.\n",
    "\n",
    "**Sara Hillström: 16h**\n",
    "\n",
    "**Felix Dunér: 16h**\n",
    "\n",
    "*\tThe solutions and answers to the theoretical and practical problems, including LaTeX math-mode equations, plots and tables etc.\n",
    "*\tAll plots/results should be visible such that the notebook does not have to be run. But the code in the notebook should reproduce the plots/results if we choose to do so.<br/>\n",
    "\n",
    "*Before submitting:*\n",
    "*   Make sure that your code can run on another computer. That all plots can show on another computer including all your writing. It is good to check if your code can run here: https://colab.research.google.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Self-check**<br/>\n",
    "Is all the required information included? Have you answered all questions to the best of your ability? Anything else you can easily check? (details, terminology, arguments, clearly stated answers etc.?) Does your notebook run and can reproduce the results, plots and tables?\n",
    "\n",
    "Do not submit an incomplete assignment! We are available to help you, and you\n",
    "can receive a short extension if you contact us.\n",
    "\n",
    "**Grading**<br/>\n",
    "Grading will be based on a qualitative assessment of each assignment. It is important to:\n",
    "*\tPresent clear arguments\n",
    "*\tPresent the results in a pedagogical way\n",
    "*\tShow understanding of the topics (e.g, write a pseudocode) \n",
    "*\tGive correct solutions\n",
    "*\tMake sure that the code is well commented \n",
    "\n",
    "**Again, as mentioned in general guidelines, all code should be written here. And this same ipython notebook file (Assignment5_Reinforcement_Learning.ipynb) should be submitted with answers and code written in it. No separate file will be accepted.** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primer\n",
    "\n",
    "## Decision Making\n",
    "The problem of **decision making under uncertainty** (commonly known as **reinforcement learning**) can be broken down into\n",
    "two parts. First, how do we learn about the world? This involves both the\n",
    "problem of modeling our initial uncertainty about the world, and that of drawing conclusions from evidence and our initial belief. Secondly, given what we\n",
    "currently know about the world, how should we decide what to do, taking into\n",
    "account future events and observations that may change our conclusions?\n",
    "Typically, this will involve creating long-term plans covering possible future\n",
    "eventualities. That is, when planning under uncertainty, we also need to take\n",
    "into account what possible future knowledge could be generated when implementing our plans. Intuitively, executing plans which involve trying out new\n",
    "things should give more information, but it is hard to tell whether this information will be beneficial. The choice between doing something which is already\n",
    "known to produce good results and experiment with something new is known\n",
    "as the **exploration-exploitation dilemma**.\n",
    "\n",
    "## The exploration-exploitation trade-off\n",
    "\n",
    "Consider the problem of selecting a restaurant to go to during a vacation. Lets say the\n",
    "best restaurant you have found so far was **Les Epinards**. The food there is\n",
    "usually to your taste and satisfactory. However, a well-known recommendations\n",
    "website suggests that **King’s Arm** is really good! It is tempting to try it out. But\n",
    "there is a risk involved. It may turn out to be much worse than **Les Epinards**,\n",
    "in which case you will regret going there. On the other hand, it could also be\n",
    "much better. What should you do?\n",
    "It all depends on how much information you have about either restaurant,\n",
    "and how many more days you’ll stay in town. If this is your last day, then it’s\n",
    "probably a better idea to go to **Les Epinards**, unless you are expecting **King’s\n",
    "Arm** to be significantly better. However, if you are going to stay there longer,\n",
    "trying out **King’s Arm** is a good bet. If you are lucky, you will be getting much\n",
    "better food for the remaining time, while otherwise you will have missed only\n",
    "one good meal out of many, making the potential risk quite small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "* To make things concrete, we will first focus on decision making under **no** uncertainity, i.e, given we have a world model, we can calculate the exact and optimal actions to take in it. We will first introduce **Markov Decision Process (MDP)** as the world model. Then we give one algorithm (out of many) to solve it.\n",
    "\n",
    "\n",
    "* Next, we will work through one type of reinforcement learning algorithm called Q-learning. Q-learning is an algorithm for making decisions under uncertainity, where uncertainity is over the possible world model (here MDP). It will find the optimal policy for the **unknown** MDP, assuming we do infinite exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Decision Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov Decision Process (MDP) provides a mathematical framework for modeling sequential decision making under uncertainty. A MDP consists of five parts: the specific decision times, the state space of the environment/system, the available actions for the decision maker, the rewards, and the transition probabilities between the states.\n",
    "\n",
    "* Decision epochs: $t={1,2,...,T}$, where $T\\leq \\infty$\n",
    "* State space: $S=\\{s_1,s_2,...,s_N\\}$ of the underlying environment\n",
    "* Action space $A=\\{a_1,a_2,...,a_K\\}$ available to the decision maker at each decision epoch\n",
    "* Reward functions $R_t = r(a_t,s_t,s_{t+1})$ for the current state and action, and the resulting next state\n",
    "* Transition probabilities $p(s'|s,a)$ that taking action $a$ in state $s$ will lead to state $s'$\n",
    "\n",
    "At a given decision epoch $t$ and system state $s_t$, the decions maker, or *agent*, chooses an action $a_t$, the system jumps to a new state $s_{t+1}$ according to the transition probability $p(s_{t+1}|s_t,a_t)$, and the agent receives a reward $r_t(s_t,a_t,s_{t+1})$. This process is then repeated for a finite or infinite number of times.\n",
    "\n",
    "A *decision policy* is a function $\\pi: s \\rightarrow a$, that gives instructions on what action to choose in each state. A policy can either be *deterministic*, meaning that the action is given for each state, or *randomized* meaning that there is a probability distribution over the set of possible actions. Given a specific policy $\\pi$ we can then compute the the *expected total reward* when starting in a given state $s_0 \\in S$, which is also known as the *value* for that state, \n",
    "\n",
    "$$V^\\pi (s_1) = E\\left[ \\sum_{t=1}^{T} r(s_t,a_t,s_{t+1}) {\\Large |} s_1\\right] = \\sum_{t=1}^{T} r(s_t,a_t,s_{t+1}) p(s_{t+1} | a_t,s_t)$$ \n",
    "\n",
    "where $a_t = \\pi(s_t)$. To ensure convergence and to control how much credit to give to future rewards, it is common to introduce a *discount factor* $\\gamma \\in [0,1]$. For instance, if you think all future rewards should count equally, you would use $\\gamma = 1$, while if you only care less about future rewards you would use $\\gamma < 1$. The expected total *discounted* reward becomes\n",
    "\n",
    "$$V^\\pi( s_1) = \\sum_{t=1}^T \\gamma^{t-1} r(s_t,a_t, s_{t+1}) p(s_{t+1} | s_t, a_t) $$\n",
    "\n",
    "Now, to find the *optimal* policy we want to find the policy $\\pi^*$ that gives the highest total reward $V^*(s)$ for all $s\\in S$. That is\n",
    "\n",
    "$$V^*(s) \\geq V^\\pi(s), s\\in S$$\n",
    "\n",
    "It turns out that a solution to the dynamic programming equation, known as the *Bellman equation*, is an optimal policy. The Bellman equation is given by\n",
    "\n",
    "$$V(s) = \\max_{a\\in A} \\left\\{\\sum_{s'\\in S} p(s'|s,a)( r(s,a,s') +\\gamma V(s')) \\right\\}$$\n",
    "\n",
    "Thus, it can be shown that if $\\pi$ is a policy such that $V^\\pi$ fulfills the Bellman equation, then $\\pi$ is an optimal policy.\n",
    "\n",
    "A real world example would be an inventory control system. Your states would be the amount of items you have in stock. Your actions would be the amount to order. The discrete time would be the days of the month. The reward would be the profit.  \n",
    "\n",
    "A major drawback of MDPs is called the \"Curse of Dimensionality\". MDPs unfortunately do not scale very well with increasing sets of states or actions.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first question covers a deterministic MPD, described as follows:\n",
    "\n",
    "* The agent starts in state **S**\n",
    "* The actions possible are **N** (north), **S** (south), **E** (east), and **W** west. \n",
    "* The transition probabilities in each box are uniform. Note, however, that you cannot move outside the grid, thus all actions are not available in every box.\n",
    "* When reaching **F**, the game ends (absorbing state).\n",
    "* The numbers in the boxes represent the rewards you receive when moving into that box. \n",
    "* Assume no discount in this model: $\\gamma = 1$\n",
    "    \n",
    "| | | |\n",
    "|----------|----------|---------|\n",
    "|-1 |1|**F**|\n",
    "|0|-1|1|  \n",
    "|-1 |0|-1|  \n",
    "|**S**|-1|1|\n",
    "\n",
    "Let $(x,y)$ denote the position in the grid, such that $S=(0,0)$ and $F=(2,3)$.\n",
    "\n",
    "**1a)** What is the optimal path of the MDP above? Is it unique? Submit the path as a single string of directions. E.g. NESW will make a circle.\n",
    "\n",
    "**Answer**: EENNN, which is **not** a unique optimal solution since we got no discount factor promoting a faster path, which in turn means we can go between points with -1 and +1 reward countless times and still get the same total reward. An alternative path is EENNWNE (same total reward, longer path).\n",
    "\n",
    "**1b)** What is the optimal policy (i.e. the optimal action in each state)?\n",
    "\n",
    "**Answer**: \n",
    "\n",
    "| | | |\n",
    "|----------|----------|---------|\n",
    "|E |E|**F**|\n",
    "|S/N/E|N/E|N|  \n",
    "|N/E |N/S/E/W|S/N|  \n",
    "|**N/E**|E|N/E|\n",
    "\n",
    "**1c)** What is expected total reward for the policy in 1b)?\n",
    "\n",
    "**Answer**: Total reward = 0 (adding together rewards from optimal policy EENNN (just plain addition since no non-determinism and no discount factor). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For larger problems we need to utilize algorithms to determine the optimal policy $\\pi^*$. *Value iteration* is one such algorithm that iteratively computes the value for each state. Recall that for a policy to be optimal, it must satisfy the Bellman equation above, meaning that plugging in a given candidate $V^*$ in the right-hand side (RHS) of the Bellman equation should result in the same $V^*$ on the left-hand side (LHS). This property will form the basis of our algorithm. Essentially, it can be shown that repeated application of the RHS to any intial value function $V^0(s)$ will eventually lead to the value $V$ which statifies the Bellman equation. Hence repeated application of the Bellman equation will also lead to the optimal value function. We can then extract the optimal policy by simply noting what actions that satisfy the equation.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** We will illustrate the value iteration algorithm by going through two iterations. Below is a 3x3 grid with the rewards given in each state. Assume now that given a certain state $s$ and action $a$, there is a probability 0.8 that that action will be performed and a probabilit 0.2 that no action is taken. For instance, if we take action **E** in state $(x,y)$ we will go to $(x+1,y)$ 80 percent of the time (given that that action is available in that state), and remain still 20 percent of the time. We will use have a discount factor $\\gamma = 0.9$. Let the initial value be $V^0(s)=0$ for all states $s\\in S$. \n",
    "\n",
    "| | | |  \n",
    "|----------|----------|---------|  \n",
    "|0|0|0|\n",
    "|0|10|0|  \n",
    "|0|0|0|  \n",
    "\n",
    "\n",
    "**Iteration 1**: The first iteration is trivial, $V^1(s)$ becomes the $\\max_a \\sum_{s'} p(s'|s,a) r(s,a,s')$ since $V^0$ was zero for all $s'$. The updated values for each state become\n",
    "\n",
    "| | | |  \n",
    "|----------|----------|---------|  \n",
    "|0|8|0|\n",
    "|8|2|8|  \n",
    "|0|8|0|  \n",
    "  \n",
    "**Iteration 2**:  \n",
    "  \n",
    "Staring with cell (0,0) (lower left corner): We find the expected value of each move:  \n",
    "Action **S**: 0  \n",
    "Action **E**: 0.8( 0 + 0.9 \\* 8) + 0.2(0 + 0.9 \\* 0) = 5.76  \n",
    "Action **N**: 0.8( 0 + 0.9 \\* 8) + 0.2(0 + 0.9 \\* 0) = 5.76  \n",
    "Action **W**: 0\n",
    "\n",
    "Hence any action between **E** and **N** would be best at this stage.\n",
    "\n",
    "Similarly for cell (1,0):\n",
    "\n",
    "Action **N**: 0.8( 10 + 0.9 \\* 2) + 0.2(0 + 0.9 \\* 8) = 10.88 (Action **N** is the maximizing action)  \n",
    "\n",
    "Similar calculations for remaining cells give us:\n",
    "\n",
    "| | | |  \n",
    "|----------|----------|---------|  \n",
    "|5.76|10.88|5.76|\n",
    "|10.88|8.12|10.88|  \n",
    "|5.76|10.88|5.76|  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "**2a)** Code the value iteration algorithm just described here, and show the converging optimal value function and the optimal policy for the above 3x3 grid.\n",
    "\n",
    "**Converging optimal value function:**\n",
    "\n",
    "| | | |  \n",
    "|----------|----------|---------|  \n",
    "|45.61|51.95|45.61|\n",
    "|51.95|48.05|51.95|  \n",
    "|45.61|51.95|45.61|  \n",
    "\n",
    "**Optimal policy:**\n",
    "\n",
    "| | | |  \n",
    "|----------|----------|---------|  \n",
    "|S/E|S|S/W|\n",
    "|E|N/S/E/W|W|  \n",
    "|N/E|N|N/W|  \n",
    "\n",
    "**2b)** Explain why the result of 2a) does not depend on the initial value $V_0$.\n",
    "\n",
    "**Answer:** The Bellman equation converges at a convergence rate determined by gamma. Since we have a discount factor smaller than 1.0, with enough iterations the effect the initial value $V_0$ has on the optimal policy once it converges is non-significant. The effect of different initial value is noticeable with just a few iterations, but still has no effect on the end result if gamma is less than 1.0. Would gamma be equal to 1.0, the initial value would have an impact on the end result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for checking surrounding values\n",
    "import operator\n",
    "\n",
    "def max_Val1(A,B,row,col):\n",
    "    \n",
    "    #transitional probabilities\n",
    "    p_move = 0.8\n",
    "    p_stay = 0.2\n",
    "    gamma = 0.9\n",
    "    \n",
    "    #empty dict for storing values\n",
    "    dict = {}\n",
    "    \n",
    "    #evaluating each direction if possible\n",
    "    try:\n",
    "        east_value = p_move * (A[row][col+1] + gamma * B[row][col+1]) + p_stay * (A[row][col] + gamma * B[row][col])\n",
    "    except IndexError:\n",
    "        pass        \n",
    "    else:\n",
    "        dict['east'] = east_value\n",
    "        \n",
    "    try:\n",
    "        south_value = A[row+1][col]\n",
    "    except IndexError:\n",
    "        pass\n",
    "    else:\n",
    "        dict['south'] = p_move * (A[row+1][col] + gamma * B[row+1][col]) + p_stay * (A[row][col] + gamma * B[row][col])\n",
    "    \n",
    "    #negtive column index not allowed\n",
    "    west_value = A[row][col-1]\n",
    "   \n",
    "    if col-1 < 0: \n",
    "        pass\n",
    "    else:\n",
    "        dict['west'] = p_move * (A[row][col-1] + gamma * B[row][col-1]) + p_stay * (A[row][col] + gamma * B[row][col])\n",
    "    \n",
    "    #negtive row index not allowed\n",
    "    north_value = A[row-1][col]\n",
    "\n",
    "    if row-1 < 0:\n",
    "        pass\n",
    "    else:\n",
    "        dict['north'] = p_move * (A[row-1][col] + gamma * B[row-1][col]) + p_stay * (A[row][col] + gamma * B[row][col])\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    return max(dict.items(), key=operator.itemgetter(1))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#value iteration algorithm\n",
    "def val_Itr1(A, max_itr):\n",
    "    \n",
    "    #temporary start matrix\n",
    "    C = np.zeros([A.shape[0], A.shape[1]], dtype=float)\n",
    "    \n",
    "    #matrix to store first iteration in\n",
    "    B = np.zeros([A.shape[0], A.shape[1]], dtype=float) \n",
    "\n",
    "    \n",
    "    for i in range(0, A.shape[0]):\n",
    "        for j in range(0, A.shape[1]):\n",
    "            B[i][j] = max_Val1(A, C, i, j)\n",
    "\n",
    "    \n",
    "    #code for 1+ iterations, using matrix from 1 iteration\n",
    "    if max_itr > 1:\n",
    "                \n",
    "        for i in range(1, max_itr):\n",
    "            \n",
    "            #temporary matrix to store results in\n",
    "            temp = np.zeros([A.shape[0], A.shape[1]], dtype=float)\n",
    "\n",
    "            for i in range(0, A.shape[0]):\n",
    "                for j in range(0, A.shape[1]):\n",
    "                    temp[i][j] = max_Val1(A, B, i, j)\n",
    "        \n",
    "            B = temp\n",
    "        \n",
    "   \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45.61292366, 51.94805195, 45.61292366],\n",
       "       [51.94805195, 48.05194805, 51.94805195],\n",
       "       [45.61292366, 51.94805195, 45.61292366]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[0, 0, 0], \n",
    "    [0, 10, 0],\n",
    "    [0, 0, 0]])\n",
    "\n",
    "val_Itr1(A,300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning (RL)\n",
    "Until now, we understood that knowing the MDP, specifically $p(s'|a,s)$ and $r(s,a,s')$ allows us to efficiently find the optimal policy using the value iteration algorithm. Reinforcement learning (RL) or decision making under uncertainity, however, arises from the question of making optimal decisions without knowing the true world model (the MDP in this case).\n",
    "\n",
    "So far we have defined the value function for a policy through $V^\\pi$. Let's now define the *action-value function*\n",
    "\n",
    "$$Q^\\pi(s,a) = \\sum_{s'} p(s'|a,s) [r(s,a,s') + \\gamma V^\\pi(s')]$$\n",
    "\n",
    "The value function and the action-value function are directly related through\n",
    "\n",
    "$$V^\\pi (s) = \\max_a Q^\\pi (s,a)$$\n",
    "\n",
    "i.e, the value of taking action $a$ in state $s$ and then following the policy $\\pi$ onwards. Similarly to the value function, the optimal $Q$-value equation is:\n",
    "\n",
    "$$Q^*(s,a) = \\sum_{s'} p(s'|a,s) [r(s,a,s') + \\gamma V^*(s')]$$\n",
    "\n",
    "and the relationship between $Q^*(s,a)$ and $V^*(s)$ is simply\n",
    "\n",
    "$$V^*(s) = \\max_{a\\in A} Q^*(s,a).$$\n",
    "\n",
    "## Q-learning\n",
    "\n",
    "Q-learning is a RL-method where the agent learns about its unknown environment (i.e. the MDP is unknown) through exploration. In each time step *t* the agent chooses an action *a* based on the current state *s*, observes the reward *r* and the next state *s'*, and repeats the process in the new state. Q-learning is then a method that allows the agent to act optimally. Here we will focus on the simplest form of Q-learning algorithms, which can be applied when all states are known to the agent, and the state and action spaces are reasonably small. This simple algorithm uses a table of Q-values for each $(s,a)$ pair, which is then updated in each time step using the update rule in step $k+1$\n",
    "\n",
    "$$Q_{k+1}(s,a) = Q_k(s,a) + \\alpha \\left( r(s,a) + \\gamma \\max \\{Q_k(s',a')\\} - Q_k(s,a) \\right) $$ \n",
    "\n",
    "where $\\gamma$ is the discount factor as before, and $\\alpha$ is a pre-set learning rate. It can be shown that this algorithm converges to the optimal policy of the underlying MDP for certain values of $\\alpha$ as long as there  is sufficient exploration. For our case, we set a constant $\\alpha=0.1$.\n",
    "\n",
    "## OpenAI Gym\n",
    "\n",
    "We shall use already available simulators for different environments (worlds) using the popular OpenAI Gym library. It just implements [different types of simulators](https://gym.openai.com/) including ATARI games. Although here we will only focus on simple ones, such as the [Chain enviroment](https://gym.openai.com/envs/NChain-v0/) illustrated below.\n",
    "![alt text](https://chalmersuniversity.box.com/shared/static/6tthbzhpofq9gzlowhr3w8if0xvyxb2b.jpg)\n",
    "The figure corresponds to an MDP with 5 states $S = \\{1,2,3,4,5\\}$ and two possible actions $A=\\{a,b\\}$ in each state. The arrows indicate the resulting transitions for each state-action pair, and the numbers correspond to the rewards for each transition.\n",
    "\n",
    "## Question 3\n",
    "You are to first familiarize with the framework using its [documentation](http://gym.openai.com/docs/), and then implement the Q-learning algorithm for the Chain enviroment (called 'NChain-v0') using default parameters. Finally print the $Q^*$ table at convergence. Take $\\gamma=0.95$. You can refer to the Q-learning Jupyter notebook shown in class, uploaded on Canvas.\n",
    "\n",
    "\n",
    "## Question 4\n",
    "\n",
    "**4a)** Define the MDP corresponding to the Chain environment above and verify that the optimal $Q^*$ value obtained using simple Q-learning is the same as the optimal value function $V^*$ for the corresponding MDP's optimal action. \n",
    "\n",
    "**4b)** What is the importance of exploration in RL? Explain with an example.\n",
    "\n",
    "**Answer:** Since a RL algorithm doesn’t know the best option beforehand, it aims to find this through exploration and exploit it. Working its way through different scenarios, the algorithm will come across some options which are better, some which are worse. This is where the exploration-exploitation trade-off come’s into practice, since we have to decide how exploring our algorithm shall be. Greedy exploration methods lays more weight on exploitation, which increases the risk of locking to one good, but not great, option and exploiting this without accessing other possibilities. Since our objective often is to find an optimal solution, this implies a great risk of not succeeding in this mission. In this lies the importance of exploration, to not settle for a good solution but to continue to seek after a better one. Although, this has to be done in a way that’s as time efficient as possible, something decaying Epsilon Greedy methods often achieves. This means a strong but decreasing focus on exploration as the options are evaluated. \n",
    "\n",
    "As a real life example, consider a couple on vacation seeking to find restaurant where they can eat dinner. Using a greedy approach, they’ll maybe try two out of the towns twelve restaurants, finding one they liked and eating there for the whole vacation. This means they might miss out on other, better options. If they were to have an Epsilon Greedy approach instead, they would try a new restaurant each night, maybe eating a couple times more at the one they liked the most but still exploring at the same rate even when identifying bad options. Lastly, using a decaying epsilon greedy approach the couple would explore intensely at first but focusing their efforts where they thought they had the best experiences as the vacation goes on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[60.13959789, 58.04133518],\n",
       "       [65.07340817, 59.37519708],\n",
       "       [70.87773885, 59.55492263],\n",
       "       [77.85060839, 59.20854125],\n",
       "       [85.95533589, 62.69720917]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Task 3\n",
    "'''\n",
    "result from Q-learning Jupyter notebook with:\n",
    "num_episodes = 60000\n",
    "gamma = 0.95 \n",
    "learning_rate = 0.1 \n",
    "epsilon = 0.5 \n",
    "'''\n",
    "res_q = np.array([[60.13959789, 58.04133518],\n",
    "       [65.07340817, 59.37519708],\n",
    "       [70.87773885, 59.55492263],\n",
    "       [77.85060839, 59.20854125],\n",
    "       [85.95533589, 62.69720917]])\n",
    "\n",
    "res_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 4a \n",
    "\n",
    "#function for checking surrounding values\n",
    "import operator\n",
    "\n",
    "#eventuellt addera att funktionen ej kan ta in negativa värden\n",
    "def max_Val2(A,B,i):\n",
    "    \n",
    "    #transitional probabilities\n",
    "    p_action = 0.8\n",
    "    p_slip = 0.2\n",
    "    gamma = 0.95\n",
    "    \n",
    "    #empty dict for storing values\n",
    "    dict = {}\n",
    "    \n",
    "    \n",
    "    #evaluating actions if possible\n",
    "    if i == 4:\n",
    "        value_A = p_action * (10 + gamma * B[4]) + p_slip * (2 + gamma * B[0])\n",
    "        value_B = p_action * (2 + gamma * B[0]) + p_slip * (10 + gamma * B[4])\n",
    "        \n",
    "    else:\n",
    "        value_A = p_action * (0 + gamma * B[i+1]) + p_slip * (2 + gamma * B[0])\n",
    "        value_B = p_action * (2 + gamma * B[0]) + p_slip * (0 + gamma * B[i+1])\n",
    "        \n",
    "    dict['A'] = value_A\n",
    "    dict['B'] = value_B\n",
    "   \n",
    "    return max(dict.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#value iteration algorithm\n",
    "def val_Itr2(A, max_itr):\n",
    "    \n",
    "    #temporary start matrix\n",
    "    C = np.zeros([A.shape[0], A.shape[1]], dtype=float)\n",
    "    \n",
    "    #matrix to store first iteration in\n",
    "    B = np.zeros([A.shape[0], A.shape[1]], dtype=float) \n",
    "\n",
    "    \n",
    "    for i in range(0, A.shape[0]):\n",
    "            B[i] = max_Val2(A, C, i)[1]\n",
    "           \n",
    "    \n",
    "    #code for 1+ iterations, using matrix from 1 iteration\n",
    "    if max_itr > 1:\n",
    "                \n",
    "        for i in range(1, max_itr):\n",
    "            \n",
    "            #temporary matrix to store results in\n",
    "            temp = np.zeros([A.shape[0], A.shape[1]], dtype=float)\n",
    "\n",
    "            for i in range(0, A.shape[0]):\n",
    "                    temp[i] = max_Val2(A, B, i)[1]\n",
    "                   \n",
    "                    \n",
    "            B = temp\n",
    "        \n",
    "   \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[61.37946685],\n",
       "       [64.89127485],\n",
       "       [69.51207485],\n",
       "       [75.59207485],\n",
       "       [83.59207485]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[0], \n",
    "              [0],\n",
    "              [0],\n",
    "              [0],\n",
    "              [0]])\n",
    "\n",
    "v_star = val_Itr2(A,300)\n",
    "\n",
    "v_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$V^*(s) = \\max_{a\\in A} Q^*(s,a).$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.23986896],\n",
       "       [ 0.18213332],\n",
       "       [ 1.365664  ],\n",
       "       [ 2.25853354],\n",
       "       [ 2.36326104]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comparing Value Iteration & Q-learning\n",
    "\n",
    "q_star = res_q[:,0].reshape(-1,1) \n",
    "\n",
    "compare = q_star - v_star\n",
    "\n",
    "compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see a small difference between $$V^*(s)$$ and  $$\\max_{a\\in A} Q^*(s,a).$$\n",
    "\n",
    "This difference most likely depends on the learning rate $\\alpha ( =0.1)$ and $\\epsilon ( =0.5)$, which are both adjustable parameters when using Q learning. When alterning these two parameters, we get other results which indicates that they have an impact on the Q learning result."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "**5a)** Give a summary of how a decision tree works and how it extends to random forests.\n",
    "\n",
    "**Answer:** A decision tree is a classification and regression method. The logic behind it is that it's supposed to help predict/classify an attribute based on previous tests. The nodes of the tree represent a question/problem, its branches represent the decisions and the leaf nodes represent the outcome of the test/possible decisions (a class label). A decision tree asks a question, and classifies the data based on the answer.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "\n",
    "A random forest utilizes a form of decision tree, but instead of each node being selected from the entire data set only a subset of the parameters are taken into consideration as candidates for each nextcoming node. Another difference is that it's built on randomly selected observations (values) rather than the entire set of observations. The forest then exists of a collection of these different decision trees, and uses the average of each tree to decide on the predicted class for a observation.\n",
    "\n",
    "Take the example on whether a person has a heart disease or not in the table below:\n",
    "\n",
    "| | | | |  \n",
    "|----------|----------|---------|---------|\n",
    "|Age over 40?|Eats junkfood 4+ days a week|Exercises 3+ times a week|**Has heartdisease?**|\n",
    "|Yes|Yes|No|**Yes**|\n",
    "|No|Yes|No|**Yes**|\n",
    "|Yes|No|Yes|**No**|\n",
    "|No|No|Yes|**No**|\n",
    "\n",
    "Where the last column represents the target.\n",
    "\n",
    "For a decision tree, all 3 parameters (age, junkfood habits, exercise habits) would be considered when deciding what node should be the root node. For an arbitrary tree in the random forest, we might only include the first two parameters as the root node, pick the second one and so on. As for the observations, we might include respondent 1 twice, respondent 2 and respondent 4.\n",
    "\n",
    "When creating decision trees, Gini impurity together with feature analysis is a helpful to use to decide which question/problem is best suited as the next coming node. Gini impurity measures the likelihood of assigning a wrong classification to a random data, and hence a low value indicates a good question for the classification.\n",
    "\n",
    "For a regular decision tree, the feature (parameter) importance is higher, meaning that the root node feature will have a higher impact on the prediction outcome than nodes further down the tree. With a random forest consisting of multiple trees with subsets of the parameters, the node order will differ from tree to tree, making the prediction less sensitive in this aspect. A regular decision tree might also overfit the data, as the accuracy improves the more splits you create. However, a regular decision tree is easier to interpret than a forest of different trees where both the observations and the parameters included vary for the different trees included in the forest.\n",
    "\n",
    "**5b)** Explain what makes reinforcement learning different from supervised learning tasks such as regression or classification.\n",
    "\n",
    "**Answer:** There are a lot of major differences between supervised learning tasks and reinforcement learning, the most evident might be that instead of using sample data like supervised learning tasks, reinforcement learning interacts with the surrounding environment to gain knowledge. So instead of analysing given data and through it generating a general formula, reinforcement learning uses the Markov’s Decision process to interact with the environment in discrete steps through observations and rewards.\n",
    "\n",
    "This difference makes these two categories better suited for different situations, with RL often used in AI applications since it has an interactive nature, while supervised learning tasks like regression and classification is often used to gain valuable insights from large amount of data and predicting future outcomes based on this historical data. Another differing aspect is the volume of data that’s used to train these two different types of methods, with supervised learning tasks often requiring large volumes of data to produce good results while in reinforcement learning data is generated throughout the process using an initial state and conditions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# References\n",
    "Primer/text based on the following references:\n",
    "* http://www.cse.chalmers.se/~chrdimi/downloads/book.pdf\n",
    "* https://github.com/olethrosdc/ml-society-science/blob/master/notes.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
